const AudioLDMMock = require('../mocks/audioldm-service');
const { XenakisPromptEnhancer } = require('../tests/prompt-enhancement.test');
const SpectralSieve = require('./spectral-sieve');
const Logger = require('./logger');
const ParameterProcessor = require('./parameter-processor');

class XenakisLDMPipeline {
    constructor(config = {}) {
        this.config = {
            debug: true,
            enableVisualization: true,
            ...config
        };

        this.audioldm = new AudioLDMMock(config.audioldm);
        this.enhancer = new XenakisPromptEnhancer();
        this.spectralSieve = new SpectralSieve({
            ...config.sieve,
            visualization: this.config.enableVisualization
        });
    }

    async generate(basePrompt, parameters) {
        try {
            Logger.section('XenakisLDM Pipeline Generation');

            // Validate and normalize parameters
            const normalizedParams = ParameterProcessor.validateAndNormalize(parameters);
            Logger.info('Normalized parameters:', normalizedParams);

            // Step 1: Enhance prompt with mathematical parameters
            const enhancedPrompt = this.enhancer.enhance(basePrompt, normalizedParams);
            Logger.info('Enhanced prompt:', enhancedPrompt);

            // Step 2: Generate audio using enhanced prompt
            Logger.info('Generating base audio...');
            const rawAudio = await this.audioldm.generateAudio(enhancedPrompt, {
                duration: normalizedParams.duration
            });

            if (!rawAudio || !rawAudio.getChannelData) {
                throw new Error('Invalid audio generated by AudioLDM');
            }

            // Step 3: Apply mathematical transformations
            Logger.info('Applying mathematical transformations...');
            const processedAudio = await this._applyTransformations(rawAudio, normalizedParams);

            return {
                prompt: enhancedPrompt,
                rawAudio,
                processedAudio,
                parameters: normalizedParams
            };
        } catch (error) {
            Logger.info('Pipeline error:', error.message);
            throw error;
        }
    }

    async _applyTransformations(buffer, params) {
        try {
            let audio = this._cloneAudioBuffer(buffer);

            // Apply transforms in sequence, checking for valid parameters
            if (params.stochastic) {
                Logger.info('Applying stochastic transform...');
                audio = this._applyStochasticTransform(audio, params.stochastic);

                if (!audio || !audio.getChannelData) {
                    throw new Error('Invalid audio after stochastic transformation');
                }
            }

            if (params.sieve) {
                Logger.info('Applying spatial-spectral sieve transform...');
                audio = await this.spectralSieve.transform(audio, params.sieve);

                if (!audio || !audio.getChannelData) {
                    throw new Error('Invalid audio after spectral transformation');
                }
            }

            if (params.cellular) {
                Logger.info('Applying cellular automata transform...');
                audio = this._applyCellularTransform(audio, params.cellular);

                if (!audio || !audio.getChannelData) {
                    throw new Error('Invalid audio after cellular transformation');
                }
            }

            return audio;
        } catch (error) {
            Logger.info('Transformation error:', error.message);
            throw error;
        }
    }

    _applyStochasticTransform(buffer, params) {
        const { variance = 0.1, distribution = {} } = params;
        const result = this._cloneAudioBuffer(buffer);

        // Apply stochastic transformation based on distribution type
        const distributionFunc = this._getDistributionFunction(
            distribution.type || 'gaussian',
            distribution
        );

        for (let c = 0; c < buffer.numberOfChannels; c++) {
            const data = result.getChannelData(c);
            for (let i = 0; i < data.length; i++) {
                const noise = distributionFunc() * variance;
                data[i] = Math.max(-1, Math.min(1, data[i] + noise));
            }
        }

        return result;
    }

    _getDistributionFunction(type, params) {
        switch (type.toLowerCase()) {
            case 'gaussian':
                return () => {
                    const u1 = Math.random();
                    const u2 = Math.random();
                    return Math.sqrt(-2 * Math.log(u1)) *
                           Math.cos(2 * Math.PI * u2);
                };

            case 'uniform':
                return () => Math.random() * 2 - 1;

            default:
                return () => Math.random() * 2 - 1;
        }
    }

    _applyCellularTransform(buffer, params) {
        const { rule = 110, dimensions = 1, interaction = {} } = params;
        const result = this._cloneAudioBuffer(buffer);

        for (let c = 0; c < buffer.numberOfChannels; c++) {
            const data = result.getChannelData(c);

            if (dimensions === 1) {
                this._apply1DCA(data, rule, interaction);
            } else {
                this._apply2DCA(data, rule, interaction);
            }
        }

        return result;
    }

    _apply1DCA(data, rule, interaction) {
        const state = new Uint8Array(data.length);
        const newState = new Uint8Array(data.length);
        const radius = interaction.radius || 1;

        // Initialize CA state from audio data
        for (let i = 0; i < data.length; i++) {
            state[i] = data[i] > 0 ? 1 : 0;
        }

        // Apply CA rule with interaction radius
        for (let i = radius; i < data.length - radius; i++) {
            let pattern = 0;
            for (let r = -radius; r <= radius; r++) {
                pattern = (pattern << 1) | state[i + r];
            }
            newState[i] = (rule >> pattern) & 1;
        }

        // Convert CA state back to audio with smooth transitions
        const strength = interaction.strength || 0.5;
        for (let i = 0; i < data.length; i++) {
            const target = newState[i] * 2 - 1;
            data[i] = data[i] * (1 - strength) + target * strength;
        }
    }

    _apply2DCA(data, rule, interaction) {
        // For now, fall back to 1D CA
        this._apply1DCA(data, rule, interaction);
    }

    _cloneAudioBuffer(buffer) {
        if (!buffer || typeof buffer.numberOfChannels !== 'number') {
            throw new Error('Invalid audio buffer');
        }

        const result = {
            sampleRate: buffer.sampleRate,
            numberOfChannels: buffer.numberOfChannels,
            duration: buffer.duration,
            length: buffer.length,
            _channels: []
        };

        for (let i = 0; i < buffer.numberOfChannels; i++) {
            const channelData = buffer.getChannelData(i);
            if (!channelData || !channelData.length) {
                throw new Error(`Invalid channel data for channel ${i}`);
            }
            result._channels[i] = new Float32Array(channelData);
        }

        result.getChannelData = function(channel) {
            if (channel >= this.numberOfChannels) {
                throw new Error('Invalid channel index');
            }
            return this._channels[channel];
        };

        return result;
    }
}

module.exports = XenakisLDMPipeline;
