{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 55, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/alex/testing-browser/audio-learning-hub/src/app/api/chat/route.ts"],"sourcesContent":["import { NextResponse } from 'next/server';\r\n\r\nconst TIMEOUT_MS = 300000; // 5 minutes - Ollama can take time with context\r\nconst MAX_RETRIES = 3;\r\nconst RETRY_DELAY_MS = 1000;\r\n\r\nconst OLLAMA_ENDPOINT = 'http://127.0.0.1:11434';\r\n\r\nasync function fetchWithRetry(url: string, options: RequestInit, retries = MAX_RETRIES): Promise<Response> {\r\n  const controller = new AbortController();\r\n  const timeoutId = setTimeout(() => controller.abort(), TIMEOUT_MS);\r\n\r\n  try {\r\n    const response = await fetch(url, {\r\n      ...options,\r\n      signal: controller.signal,\r\n    });\r\n    clearTimeout(timeoutId);\r\n\r\n    if (!response.ok) {\r\n      throw new Error(`HTTP error! status: ${response.status}`);\r\n    }\r\n\r\n    return response;\r\n  } catch (error: any) {\r\n    clearTimeout(timeoutId);\r\n    \r\n    if (retries > 0 && error.name === 'AbortError') {\r\n      console.log(`Retrying request, ${retries} attempts remaining...`);\r\n      await new Promise(resolve => setTimeout(resolve, RETRY_DELAY_MS));\r\n      return fetchWithRetry(url, options, retries - 1);\r\n    }\r\n    throw error;\r\n  }\r\n}\r\n\r\nasync function ollamaChat(model: string, messages: any[], stream = false) {\r\n  const requestBody = {\r\n    model,\r\n    messages,\r\n    stream,\r\n    options: {\r\n      temperature: 0.7,\r\n      num_predict: 1024,\r\n      top_k: 40,\r\n      top_p: 0.9,\r\n      repeat_penalty: 1.1,\r\n    },\r\n  };\r\n\r\n  const response = await fetchWithRetry(`${OLLAMA_ENDPOINT}/api/chat`, {\r\n    method: 'POST',\r\n    headers: {\r\n      'Content-Type': 'application/json',\r\n    },\r\n    body: JSON.stringify(requestBody),\r\n  });\r\n\r\n  return response;\r\n}\r\n\r\nexport async function POST(req: Request) {\r\n  try {\r\n    const body = await req.json();\r\n    const { model, messages, stream = false } = body;\r\n\r\n    console.log('Received chat request:', body);\r\n\r\n    const response = await ollamaChat(model, messages, stream);\r\n\r\n    if (stream) {\r\n      // Handle streaming response\r\n      const reader = response.body?.getReader();\r\n      const encoder = new TextEncoder();\r\n      const decoder = new TextDecoder();\r\n\r\n      return new Response(\r\n        new ReadableStream({\r\n          async start(controller) {\r\n            try {\r\n              while (true) {\r\n                const { done, value } = await reader!.read();\r\n                if (done) break;\r\n\r\n                const chunk = decoder.decode(value);\r\n                const lines = chunk.split('\\n');\r\n\r\n                for (const line of lines) {\r\n                  if (line.trim()) {\r\n                    controller.enqueue(encoder.encode(`data: ${line}\\n\\n`));\r\n                  }\r\n                }\r\n              }\r\n              controller.close();\r\n            } catch (error) {\r\n              controller.error(error);\r\n            }\r\n          },\r\n        }),\r\n        {\r\n          headers: {\r\n            'Content-Type': 'text/event-stream',\r\n            'Cache-Control': 'no-cache',\r\n            Connection: 'keep-alive',\r\n          },\r\n        }\r\n      );\r\n    } else {\r\n      // Handle regular response\r\n      const data = await response.json();\r\n      console.log('API response:', data);\r\n      return NextResponse.json(data);\r\n    }\r\n  } catch (error: any) {\r\n    console.error('API error:', error);\r\n    return NextResponse.json(\r\n      {\r\n        error: `Failed to get AI response: ${error.message}`,\r\n        details: error.stack,\r\n      },\r\n      { status: 500 }\r\n    );\r\n  }\r\n}\r\n"],"names":[],"mappings":";;;AAAA;;AAEA,MAAM,aAAa,QAAQ,gDAAgD;AAC3E,MAAM,cAAc;AACpB,MAAM,iBAAiB;AAEvB,MAAM,kBAAkB;AAExB,eAAe,eAAe,GAAW,EAAE,OAAoB,EAAE,UAAU,WAAW;IACpF,MAAM,aAAa,IAAI;IACvB,MAAM,YAAY,WAAW,IAAM,WAAW,KAAK,IAAI;IAEvD,IAAI;QACF,MAAM,WAAW,MAAM,MAAM,KAAK;YAChC,GAAG,OAAO;YACV,QAAQ,WAAW,MAAM;QAC3B;QACA,aAAa;QAEb,IAAI,CAAC,SAAS,EAAE,EAAE;YAChB,MAAM,IAAI,MAAM,CAAC,oBAAoB,EAAE,SAAS,MAAM,EAAE;QAC1D;QAEA,OAAO;IACT,EAAE,OAAO,OAAY;QACnB,aAAa;QAEb,IAAI,UAAU,KAAK,MAAM,IAAI,KAAK,cAAc;YAC9C,QAAQ,GAAG,CAAC,CAAC,kBAAkB,EAAE,QAAQ,sBAAsB,CAAC;YAChE,MAAM,IAAI,QAAQ,CAAA,UAAW,WAAW,SAAS;YACjD,OAAO,eAAe,KAAK,SAAS,UAAU;QAChD;QACA,MAAM;IACR;AACF;AAEA,eAAe,WAAW,KAAa,EAAE,QAAe,EAAE,SAAS,KAAK;IACtE,MAAM,cAAc;QAClB;QACA;QACA;QACA,SAAS;YACP,aAAa;YACb,aAAa;YACb,OAAO;YACP,OAAO;YACP,gBAAgB;QAClB;IACF;IAEA,MAAM,WAAW,MAAM,eAAe,GAAG,gBAAgB,SAAS,CAAC,EAAE;QACnE,QAAQ;QACR,SAAS;YACP,gBAAgB;QAClB;QACA,MAAM,KAAK,SAAS,CAAC;IACvB;IAEA,OAAO;AACT;AAEO,eAAe,KAAK,GAAY;IACrC,IAAI;QACF,MAAM,OAAO,MAAM,IAAI,IAAI;QAC3B,MAAM,EAAE,KAAK,EAAE,QAAQ,EAAE,SAAS,KAAK,EAAE,GAAG;QAE5C,QAAQ,GAAG,CAAC,0BAA0B;QAEtC,MAAM,WAAW,MAAM,WAAW,OAAO,UAAU;QAEnD,IAAI,QAAQ;YACV,4BAA4B;YAC5B,MAAM,SAAS,SAAS,IAAI,EAAE;YAC9B,MAAM,UAAU,IAAI;YACpB,MAAM,UAAU,IAAI;YAEpB,OAAO,IAAI,SACT,IAAI,eAAe;gBACjB,MAAM,OAAM,UAAU;oBACpB,IAAI;wBACF,MAAO,KAAM;4BACX,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE,GAAG,MAAM,OAAQ,IAAI;4BAC1C,IAAI,MAAM;4BAEV,MAAM,QAAQ,QAAQ,MAAM,CAAC;4BAC7B,MAAM,QAAQ,MAAM,KAAK,CAAC;4BAE1B,KAAK,MAAM,QAAQ,MAAO;gCACxB,IAAI,KAAK,IAAI,IAAI;oCACf,WAAW,OAAO,CAAC,QAAQ,MAAM,CAAC,CAAC,MAAM,EAAE,KAAK,IAAI,CAAC;gCACvD;4BACF;wBACF;wBACA,WAAW,KAAK;oBAClB,EAAE,OAAO,OAAO;wBACd,WAAW,KAAK,CAAC;oBACnB;gBACF;YACF,IACA;gBACE,SAAS;oBACP,gBAAgB;oBAChB,iBAAiB;oBACjB,YAAY;gBACd;YACF;QAEJ,OAAO;YACL,0BAA0B;YAC1B,MAAM,OAAO,MAAM,SAAS,IAAI;YAChC,QAAQ,GAAG,CAAC,iBAAiB;YAC7B,OAAO,sSAAA,CAAA,eAAY,CAAC,IAAI,CAAC;QAC3B;IACF,EAAE,OAAO,OAAY;QACnB,QAAQ,KAAK,CAAC,cAAc;QAC5B,OAAO,sSAAA,CAAA,eAAY,CAAC,IAAI,CACtB;YACE,OAAO,CAAC,2BAA2B,EAAE,MAAM,OAAO,EAAE;YACpD,SAAS,MAAM,KAAK;QACtB,GACA;YAAE,QAAQ;QAAI;IAElB;AACF"}},
    {"offset": {"line": 162, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}}]
}